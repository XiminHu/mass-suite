{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cluster,mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ms = pd.read_csv('../example_data/clustering/sample1114.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Rt(min)</th>\n",
       "      <th>Average Mz</th>\n",
       "      <th>S/N average</th>\n",
       "      <th>20181114_CEC_CAL-8-no4_MSpos_1</th>\n",
       "      <th>20181114_CEC_CAL-8-no4_MSpos_2</th>\n",
       "      <th>20181114_CEC_CAL-8-no4_MSpos_3</th>\n",
       "      <th>20181114_CEC_CAL-8-no4_MSpos_4</th>\n",
       "      <th>20181114_CEC_CAL-8-no4_MSpos_5</th>\n",
       "      <th>20181114_CEC_CAL-8-no4_MSpos_6</th>\n",
       "      <th>20181114_CEC_CAL-8-no4_MSpos_7</th>\n",
       "      <th>...</th>\n",
       "      <th>20181114_SR520-Creek_Mix6A_3</th>\n",
       "      <th>20181114_SR520-Creek_Mix6B_1</th>\n",
       "      <th>20181114_SR520-Creek_Mix6B_2</th>\n",
       "      <th>20181114_SR520-Creek_Mix6B_3</th>\n",
       "      <th>20181114_SwanCreek-Dec_1</th>\n",
       "      <th>20181114_SwanCreek-Dec_2</th>\n",
       "      <th>20181114_SwanCreek-Dec_3</th>\n",
       "      <th>20181114_SwanCreek-May_1</th>\n",
       "      <th>20181114_SwanCreek-May_2</th>\n",
       "      <th>20181114_SwanCreek-May_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.381</td>\n",
       "      <td>100.03931</td>\n",
       "      <td>60.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>82</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.332</td>\n",
       "      <td>100.07604</td>\n",
       "      <td>88.07</td>\n",
       "      <td>412</td>\n",
       "      <td>754</td>\n",
       "      <td>1985</td>\n",
       "      <td>1639</td>\n",
       "      <td>2049</td>\n",
       "      <td>1796</td>\n",
       "      <td>2702</td>\n",
       "      <td>...</td>\n",
       "      <td>674</td>\n",
       "      <td>1609</td>\n",
       "      <td>1571</td>\n",
       "      <td>782</td>\n",
       "      <td>976</td>\n",
       "      <td>729</td>\n",
       "      <td>587</td>\n",
       "      <td>6437</td>\n",
       "      <td>3174</td>\n",
       "      <td>2708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.544</td>\n",
       "      <td>100.11243</td>\n",
       "      <td>111.09</td>\n",
       "      <td>4168</td>\n",
       "      <td>3547</td>\n",
       "      <td>2459</td>\n",
       "      <td>3768</td>\n",
       "      <td>3544</td>\n",
       "      <td>1695</td>\n",
       "      <td>2862</td>\n",
       "      <td>...</td>\n",
       "      <td>2282</td>\n",
       "      <td>1246</td>\n",
       "      <td>1662</td>\n",
       "      <td>2120</td>\n",
       "      <td>840</td>\n",
       "      <td>1336</td>\n",
       "      <td>1665</td>\n",
       "      <td>1200</td>\n",
       "      <td>1191</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.359</td>\n",
       "      <td>100.11253</td>\n",
       "      <td>155.25</td>\n",
       "      <td>1239</td>\n",
       "      <td>1145</td>\n",
       "      <td>1007</td>\n",
       "      <td>550</td>\n",
       "      <td>1254</td>\n",
       "      <td>781</td>\n",
       "      <td>1714</td>\n",
       "      <td>...</td>\n",
       "      <td>203706</td>\n",
       "      <td>231624</td>\n",
       "      <td>152532</td>\n",
       "      <td>231635</td>\n",
       "      <td>260914</td>\n",
       "      <td>258902</td>\n",
       "      <td>234764</td>\n",
       "      <td>234498</td>\n",
       "      <td>193185</td>\n",
       "      <td>193974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.628</td>\n",
       "      <td>101.00802</td>\n",
       "      <td>20.59</td>\n",
       "      <td>1295</td>\n",
       "      <td>1499</td>\n",
       "      <td>1508</td>\n",
       "      <td>2067</td>\n",
       "      <td>2103</td>\n",
       "      <td>2153</td>\n",
       "      <td>1500</td>\n",
       "      <td>...</td>\n",
       "      <td>18334</td>\n",
       "      <td>14693</td>\n",
       "      <td>11126</td>\n",
       "      <td>10754</td>\n",
       "      <td>14120</td>\n",
       "      <td>10229</td>\n",
       "      <td>12813</td>\n",
       "      <td>10449</td>\n",
       "      <td>9869</td>\n",
       "      <td>11369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Average Rt(min)  Average Mz  S/N average  20181114_CEC_CAL-8-no4_MSpos_1  \\\n",
       "0            8.381   100.03931        60.33                               0   \n",
       "1            2.332   100.07604        88.07                             412   \n",
       "2            2.544   100.11243       111.09                            4168   \n",
       "3            5.359   100.11253       155.25                            1239   \n",
       "4            0.628   101.00802        20.59                            1295   \n",
       "\n",
       "   20181114_CEC_CAL-8-no4_MSpos_2  20181114_CEC_CAL-8-no4_MSpos_3  \\\n",
       "0                               0                               0   \n",
       "1                             754                            1985   \n",
       "2                            3547                            2459   \n",
       "3                            1145                            1007   \n",
       "4                            1499                            1508   \n",
       "\n",
       "   20181114_CEC_CAL-8-no4_MSpos_4  20181114_CEC_CAL-8-no4_MSpos_5  \\\n",
       "0                               0                               0   \n",
       "1                            1639                            2049   \n",
       "2                            3768                            3544   \n",
       "3                             550                            1254   \n",
       "4                            2067                            2103   \n",
       "\n",
       "   20181114_CEC_CAL-8-no4_MSpos_6  20181114_CEC_CAL-8-no4_MSpos_7  ...  \\\n",
       "0                               0                               0  ...   \n",
       "1                            1796                            2702  ...   \n",
       "2                            1695                            2862  ...   \n",
       "3                             781                            1714  ...   \n",
       "4                            2153                            1500  ...   \n",
       "\n",
       "   20181114_SR520-Creek_Mix6A_3  20181114_SR520-Creek_Mix6B_1  \\\n",
       "0                            68                            82   \n",
       "1                           674                          1609   \n",
       "2                          2282                          1246   \n",
       "3                        203706                        231624   \n",
       "4                         18334                         14693   \n",
       "\n",
       "   20181114_SR520-Creek_Mix6B_2  20181114_SR520-Creek_Mix6B_3  \\\n",
       "0                           100                             0   \n",
       "1                          1571                           782   \n",
       "2                          1662                          2120   \n",
       "3                        152532                        231635   \n",
       "4                         11126                         10754   \n",
       "\n",
       "   20181114_SwanCreek-Dec_1  20181114_SwanCreek-Dec_2  \\\n",
       "0                         0                         0   \n",
       "1                       976                       729   \n",
       "2                       840                      1336   \n",
       "3                    260914                    258902   \n",
       "4                     14120                     10229   \n",
       "\n",
       "   20181114_SwanCreek-Dec_3  20181114_SwanCreek-May_1  \\\n",
       "0                         0                         0   \n",
       "1                       587                      6437   \n",
       "2                      1665                      1200   \n",
       "3                    234764                    234498   \n",
       "4                     12813                     10449   \n",
       "\n",
       "   20181114_SwanCreek-May_2  20181114_SwanCreek-May_3  \n",
       "0                         0                         0  \n",
       "1                      3174                      2708  \n",
       "2                      1191                      1217  \n",
       "3                    193185                    193974  \n",
       "4                      9869                     11369  \n",
       "\n",
       "[5 rows x 157 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ms = d_ms.rename(columns={'Average Rt(min)': 'Average RT (min)', 'Average Mz': 'Average m/z', 'S/N average': 'Average sn'})\n",
    "d_ms.insert(3, \"Average score\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_clean(dataframe, rt_range=[0, 30], mz_range=[0, 1200], sn_thres=3, score_thres=0, area_thres=5000): #Update with *args or **args in future updates\n",
    "    #Area thres update\n",
    "    drop_index = np.argwhere(np.asarray(dataframe[dataframe.columns[4:]].max(axis=1)) < area_thres).reshape(1,-1)\n",
    "    df_c = dataframe.drop(drop_index[0])\n",
    "    \n",
    "    df_c = df_c[(df_c['Average RT (min)'] > rt_range[0]) & (df_c['Average RT (min)'] < rt_range[1])]\n",
    "    df_c = df_c[(df_c['Average m/z'] > mz_range[0]) & (df_c['Average m/z'] < mz_range[1])]\n",
    "    df_c = df_c[df_c['Average sn'] >= sn_thres]\n",
    "    df_c = df_c[df_c['Average score'] >= score_thres]\n",
    "    df_c.reset_index(inplace=True)\n",
    "    df_c.drop(columns=['index'],inplace=True)\n",
    "    \n",
    "    return df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = d_clean(d_ms,rt_range = [1,30], mz_range = [200,800], area_thres=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distinguish between sample and blank\n",
    "col_blank = [col for col in df_c.columns if 'CEC' in col or 'Blank' in col or 'ISTD' in col or 'Wash' in col or 'Shutdown' in col]\n",
    "col_sample = [col for col in df_c.columns if col not in col_blank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample vs blank threshold\n",
    "samplevsblank_thres = 10\n",
    "d_sample = df_c[df_c[col_sample[4:]].max(axis=1) / df_c[col_blank].mean(axis=1) > samplevsblank_thres][col_sample]\n",
    "d_sample.reset_index(inplace=True)\n",
    "d_sample.drop(columns=['index'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise removal from triplicates\n",
    "trip_list = [list(i) for j, i in groupby(d_sample.columns[4:], lambda a: a.split('_')[1])] #Needs to define 1. parser 2. position of parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:53<00:40, 10.14s/it]"
     ]
    }
   ],
   "source": [
    "empty_tol = 0\n",
    "cv_tol = 5\n",
    "\n",
    "for triplicate in tqdm(trip_list):\n",
    "    for index, row in d_sample[triplicate].iterrows():\n",
    "        if (row == 0).sum() > empty_tol:\n",
    "            d_sample.loc[index, triplicate] = 0\n",
    "            #Filling the gaps and check variance? --- coefficient of variation\n",
    "        elif row.std() / row.mean() > cv_tol:\n",
    "            d_sample.loc[index, triplicate] = 0 #If delete or reduce all number to avg?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Double check if any empty columns and clean up -- deal with all samples\n",
    "d_sample = d_sample[(d_sample.iloc[:,4:]!=0).sum(1) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with only dilution series\n",
    "col_di = [col for col in d_sample.columns if 'SR520-Cal' in col]\n",
    "d_dilu = d_sample[col_di]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization\n",
    "#Normalization to 0 1 scale\n",
    "#c_data = d_sample[4:].values #returns a numpy array\n",
    "c_data = d_dilu.values\n",
    "\n",
    "\n",
    "#Normalized to absolute values\n",
    "c_norm = []\n",
    "for row in c_data:\n",
    "    c_norm.append(row/max(row))\n",
    "c_norm = np.asarray(c_norm)\n",
    "#Normalized to relative values\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# x_scaled = min_max_scaler.fit_transform(c_data.T)\n",
    "# df=pd.DataFrame(x_scaled)\n",
    "d_norm = pd.DataFrame(c_norm)\n",
    "d_norm.insert(0,\"RT\", d_sample['Average RT (min)'].tolist())\n",
    "d_norm.insert(1,\"MZ\", d_sample['Average m/z'].tolist())\n",
    "d_norm = d_norm.dropna()\n",
    "d_norm = d_norm.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_calc(df):\n",
    "    cluster = []\n",
    "    clusters = []\n",
    "    cl = []\n",
    "    noise = []\n",
    "    df = df.reset_index(drop=True)\n",
    "    while len(df) > 0:\n",
    "        for row in range(len(df)):\n",
    "            feature_1 = df.iloc[0]\n",
    "            feature_2 = df.iloc[row]\n",
    "            corr, p_val = scipy.stats.pearsonr(df.iloc[0, 2:], df.iloc[row, 2:])\n",
    "            if p_val < 0.05:\n",
    "                cl.append(row)\n",
    "                cluster += [feature_2]\n",
    "            else:\n",
    "                pass\n",
    "        if len(cluster) == 1:\n",
    "            noise += [cluster]\n",
    "            cluster = []\n",
    "        else:\n",
    "            clusters += [cluster]\n",
    "            cluster = []\n",
    "        df = df.drop(cl)\n",
    "        df = df.reset_index(drop=True)\n",
    "        cl = []\n",
    "    return clusters, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rt=[]\n",
    "mz=[]\n",
    "for i in range(len(a)):\n",
    "    for j in range(len(a[i])):\n",
    "        rt.append(a[i][j].loc['RT'])\n",
    "        mz.append(a[i][j].loc['MZ'])\n",
    "    plt.scatter(rt,mz,label=i)\n",
    "    rt=[]\n",
    "    mz=[]\n",
    "rt2=[]\n",
    "mz2=[]\n",
    "for k in range(len(b)):\n",
    "    rt2.append(b[k][0].loc['RT'])\n",
    "    mz2.append(b[k][0].loc['MZ'])\n",
    "plt.scatter(rt2,mz2,label='noise')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=trend_calc(d_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_calc(df):\n",
    "    cluster = []\n",
    "    clusters = []\n",
    "    cl = []\n",
    "    noise = []\n",
    "    df = df.reset_index(drop=True)\n",
    "    while len(df) > 0:\n",
    "        for row in range(len(df)):\n",
    "            feature_1 = df.iloc[0]\n",
    "            feature_2 = df.iloc[row]\n",
    "            corr, p_val = scipy.stats.spearmanr(df.iloc[0, 2:], df.iloc[row, 2:])\n",
    "            if p_val < 0.05:\n",
    "                cl.append(row)\n",
    "                cluster += [feature_2]\n",
    "            else:\n",
    "                pass\n",
    "        if len(cluster) == 1:\n",
    "            noise += [cluster]\n",
    "            cluster = []\n",
    "        else:\n",
    "            clusters += [cluster]\n",
    "            cluster = []\n",
    "        df = df.drop(cl)\n",
    "        df = df.reset_index(drop=True)\n",
    "        cl = []\n",
    "    return clusters, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,d=trend_calc(d_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt=[]\n",
    "mz=[]\n",
    "for i in range(len(c)):\n",
    "    for j in range(len(c[i])):\n",
    "        rt.append(c[i][j].loc['RT'])\n",
    "        mz.append(c[i][j].loc['MZ'])\n",
    "    plt.scatter(rt,mz,label=i)\n",
    "    rt=[]\n",
    "    mz=[]\n",
    "rt2=[]\n",
    "mz2=[]\n",
    "for k in range(len(d)):\n",
    "    rt2.append(d[k][0].loc['RT'])\n",
    "    mz2.append(d[k][0].loc['MZ'])\n",
    "plt.scatter(rt2,mz2,label='noise')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_calc(df):\n",
    "    cluster = []\n",
    "    clusters = []\n",
    "    cl = []\n",
    "    noise = []\n",
    "    df = df.reset_index(drop=True)\n",
    "    while len(df) > 0:\n",
    "        for row in range(len(df)):\n",
    "            feature_1 = df.iloc[0]\n",
    "            feature_2 = df.iloc[row]\n",
    "            corr, p_val = scipy.stats.kendalltau(df.iloc[0, 2:], df.iloc[row, 2:])\n",
    "            if p_val < 0.05:\n",
    "                cl.append(row)\n",
    "                cluster += [feature_2]\n",
    "            else:\n",
    "                pass\n",
    "        if len(cluster) == 1:\n",
    "            noise += [cluster]\n",
    "            cluster = []\n",
    "        else:\n",
    "            clusters += [cluster]\n",
    "            cluster = []\n",
    "        df = df.drop(cl)\n",
    "        df = df.reset_index(drop=True)\n",
    "        cl = []\n",
    "    return clusters, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e,f=trend_calc(d_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt=[]\n",
    "mz=[]\n",
    "for i in range(len(e)):\n",
    "    for j in range(len(e[i])):\n",
    "        rt.append(e[i][j].loc['RT'])\n",
    "        mz.append(e[i][j].loc['MZ'])\n",
    "    plt.scatter(rt,mz,label=i)\n",
    "    rt=[]\n",
    "    mz=[]\n",
    "rt2=[]\n",
    "mz2=[]\n",
    "for k in range(len(f)):\n",
    "    rt2.append(f[k][0].loc['RT'])\n",
    "    mz2.append(f[k][0].loc['MZ'])\n",
    "plt.scatter(rt2,mz2,label='noise')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no 0 is acceptable in the clustermap -- eye balling estimation?\n",
    "sns.clustermap(d_norm.values,cmap='Reds',col_cluster=True,yticklabels=False,xticklabels=False)\n",
    "plt.title('Clustermap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# whole batch or only dilution series\n",
    "whole batch to start with the testing, then apply extra filter to filter out cases, one exist both in source and non-source sample and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization of the dataset for statistical analysis -- unsupervised machine learning\n",
    "#Q: is the normalization needed to terminate the effect of peak area variation?\n",
    "#option: random forest, som, pca+k-means， t-sne+dbscan, autoencoder\n",
    "#option2: non-parametric test\n",
    "#Normalized data-c_data\n",
    "d_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering visualization sample -- scatter plot\n",
    "X=d_norm\n",
    "#msfit = ms.fit(X)\n",
    "db = DBSCAN(eps=0.9, min_samples=5).fit(X)\n",
    "\n",
    "d_label = d_sample.iloc[d_norm.index]\n",
    "d_label['label'] = db.labels_\n",
    "\n",
    "#Plot\n",
    "unique_labels = set(d_label['label'])\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "        \n",
    "    plt.plot(d_label[d_label['label']==k]['Average RT (min)'], d_label[d_label['label']==k]['Average m/z'], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k')\n",
    "    #plt.colorbar()\n",
    "plt.xlabel('rt')\n",
    "plt.ylabel('mz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Clustering visualization sample -- trend plot\n",
    "X=d_norm.copy()\n",
    "#msfit = ms.fit(X)\n",
    "db = DBSCAN(eps=0.9, min_samples=5).fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "#Plot\n",
    "unique_labels = set(db.labels_)\n",
    "\n",
    "for i,k in enumerate(unique_labels):\n",
    "    indexlist = list(np.argwhere(labels==k).reshape(1,-1)[0])\n",
    "    sns.clustermap(X.iloc[indexlist].values,cmap='Reds',col_cluster=True,yticklabels=False,xticklabels=False,figsize=(5,5))\n",
    "    plt.title('Clustermap')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-para testing ideas -- hypothesis testing\n",
    "similar to alignment, compare row to row trend/statistical difference and then assign neighbours as same group\n",
    "\n",
    "ref:https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = d_norm.iloc[1]\n",
    "data2 = d_norm.iloc[500]\n",
    "plt.scatter(d_norm.iloc[4], d_norm.iloc[400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearson’s Correlation Coefficient\n",
    "from scipy.stats import pearsonr\n",
    "count = 1\n",
    "stat, p = pearsonr(data1, data2)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    count += 1\n",
    "    print('Probably independent')\n",
    "else:\n",
    "    print('Probably dependent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the Spearman's Rank Correlation Test\n",
    "from scipy.stats import spearmanr\n",
    "stat, p = spearmanr(data1, data2)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('Probably independent')\n",
    "else:\n",
    "    print('Probably dependent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the Kendall's Rank Correlation Test\n",
    "from scipy.stats import kendalltau\n",
    "stat, p = kendalltau(data1, data2)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('Probably independent')\n",
    "else:\n",
    "    print('Probably dependent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the Chi-Squared Test\n",
    "from scipy.stats import chi2_contingency\n",
    "table = [data1,data2]\n",
    "stat, p, dof, expected = chi2_contingency(table)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('Probably independent')\n",
    "else:\n",
    "    print('Probably dependent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the Mann-Whitney U Test --check for distribution\n",
    "from scipy.stats import mannwhitneyu\n",
    "stat, p = mannwhitneyu(data1, data2)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('Probably the same distribution')\n",
    "else:\n",
    "    print('Probably different distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the Kruskal-Wallis H Test\n",
    "from scipy.stats import kruskal\n",
    "stat, p = kruskal(data1, data2)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('Probably the same distribution')\n",
    "else:\n",
    "    print('Probably different distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing data_pairwise\n",
    "if they are similar --> assign to cluster\n",
    "elif not --> assign a new clutser\n",
    "\n",
    "similar to alignment, do we wanna update the cluster information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparison plot -- different algorithm with clustering result as color label in the mz/rt scatter plot\n",
    "#Post filter--some cpd show up in dilution but not other samples, and vice versa\n",
    "#Prediction model based on clustering information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
